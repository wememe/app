'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.deploy = exports.handleFile = exports.readFile = undefined;

var _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; };

exports.upload = upload;
exports.deleteRemoved = deleteRemoved;
exports.sync = sync;
exports.shouldBeZipped = shouldBeZipped;

var _util = require('util');

var _util2 = _interopRequireDefault(_util);

var _path = require('path');

var _path2 = _interopRequireDefault(_path);

var _zlib = require('zlib');

var _zlib2 = _interopRequireDefault(_zlib);

var _globrex = require('globrex');

var _globrex2 = _interopRequireDefault(_globrex);

var _awsSdk = require('aws-sdk');

var _awsSdk2 = _interopRequireDefault(_awsSdk);

var _coFsExtra = require('co-fs-extra');

var _coFsExtra2 = _interopRequireDefault(_coFsExtra);

var _co = require('co');

var _co2 = _interopRequireDefault(_co);

var _cloudfront = require('./cloudfront');

var _utils = require('./utils');

var utils = _interopRequireWildcard(_utils);

var _MSG = require('./MSG');

var MSG = _interopRequireWildcard(_MSG);

function _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = obj[key]; } } newObj.default = obj; return newObj; } }

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

/**
 * Uploads a file to AWS S3 bucket.
 * @param  {Object} client AWS Client object.
 * @param  {Object} file   File details of a file to be uploaded.
 * @param  {Object} opts   Object with additional AWS parameters.
 * @return {Promise}        Returns a promise which resolves with a log message of upload status.
 */
function upload(client, file, opts, filePrefix, ext, fileName) {
  return new Promise(function (resolve, reject) {
    opts = Object.assign({
      ACL: 'public-read'
    }, opts);

    var params = Object.assign({}, utils.buildUploadParams(file, filePrefix, ext, fileName), opts);
    params = utils.handleETag(params);
    var dest = params.Key;

    // Upload the file to s3.
    client.putObject(params, function (err) {
      if (err) {
        return reject(_util2.default.format(MSG.ERR_UPLOAD, err, err.stack));
      }

      return resolve(_util2.default.format(MSG.UPLOAD_SUCCESS, params.Bucket, dest));
    });
  });
}

var listAllKeys = function listAllKeys(client, params) {
  var out = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [];
  return new Promise(function (resolve, reject) {
    client.listObjectsV2(params).promise().then(function (_ref) {
      var Contents = _ref.Contents,
          IsTruncated = _ref.IsTruncated,
          NextContinuationToken = _ref.NextContinuationToken;

      console.log('listObjects IsTruncated: %s', IsTruncated);
      var s3files = Contents.map(function (item) {
        return item.Key;
      });
      out = out.concat(s3files);
      !IsTruncated ? resolve(out) : resolve(listAllKeys(client, Object.assign(params, { ContinuationToken: NextContinuationToken }), out));
    }).catch(reject);
  });
};

function deleteRemoved(client, files, options) {

  var params = {
    Bucket: options.bucket
  };

  return new Promise(function (resolve, reject) {

    listAllKeys(client, params).then(function (allKeys) {
      console.log('allKeys length: %s', allKeys.length);
      var localFiles = files.map(function (item) {
        return item.substr(options.cwd.length);
      });
      console.log('localFiles length: %s', localFiles.length);
      var toDelete = allKeys.filter(function (item) {
        return !localFiles.includes(item);
      });

      // If deleteRemoved argument is entered, filter files on this pattern
      if (options.deleteRemoved !== true) {
        var matchReg = (0, _globrex2.default)(options.deleteRemoved, { extended: true, globstar: true }).regex;
        console.log('Filtering files to delete on: ', matchReg);
        toDelete = toDelete.filter(function (item) {
          return matchReg.test(item);
        });
      }

      if (toDelete.length > 0) {

        console.log('Deleting files: %s', toDelete);

        var i = void 0,
            j = void 0,
            tempDeletes = void 0;
        var chunk = 1000;
        for (i = 0, j = toDelete.length; i < j; i += chunk) {
          tempDeletes = toDelete.slice(i, i + chunk).map(function (item) {
            return { Key: item };
          });

          console.log('Deleting chunk: %s', tempDeletes.length);

          var _params = {
            Bucket: options.bucket,
            Delete: {
              Objects: tempDeletes
            }
          };

          client.deleteObjects(_params, function (err, data) {
            if (err) {
              console.log('Error while Deleting: ', err);
              return reject(_util2.default.format(MSG.ERR_UPLOAD, err, err.stack));
            } // an error occurred

            return resolve(_util2.default.format(MSG.DELETE_SUCCESS, toDelete));
          });
        }
      } else {
        console.log('No files to delete.');
      }
    }).catch(console.log);
  });
}

/**
 * Checks if file is already in the S3 bucket.
 * @param  {Object}  client         AWS Client object.
 * @param  {Object}  file           File details of a file to check.
 * @param  {Object}  opts           Object with additional AWS parameters.
 * @param  {Boolean} preventUpdates Prevent updating the object, even if changed
 * @return {Promise}                Returns a promise which rejects if file already exists,
 *                                  and doesn't need update. Otherwise fulfills.
 */
function sync(client, file, filePrefix, opts, preventUpdates, fileName) {
  return new Promise(function (resolve, reject) {
    var expectedHash = utils.createMd5Hash(file.contents);
    var params = {
      IfNoneMatch: expectedHash,
      Bucket: opts.Bucket
    };
    if (!preventUpdates) {
      params.IfUnmodifiedSince = file.stat.mtime;
    }
    Object.assign(params, utils.buildBaseParams(file, filePrefix, fileName));
    client.headObject(params, function (err, data) {
      if (err && (err.statusCode === 304 || err.statusCode === 412)) {
        return reject(_util2.default.format(MSG.SKIP_MATCHES, params.Key));
      }

      if (preventUpdates && data) {
        return reject(_util2.default.format(MSG.ERR_CHECKSUM, expectedHash, data.ETag, params.Key));
      }

      if (data || err.statusCode === 404) {
        return resolve();
      }

      reject(_util2.default.format(MSG.ABORT_UPLOAD, err.code, err.message, params.Key));
    });
  });
}

function shouldBeZipped(filepath, gzip) {
  if (gzip === true) return true;

  if (Array.isArray(gzip)) {
    var ext = _path2.default.extname(filepath); // ext would be ".js" or alike
    if (ext && gzip.includes(ext.substr(1))) {
      return true;
    }
  }

  return false;
}

/**
 * Checks if the provided path is a file or directory.
 * If it is a file, it returns file details object.
 * Otherwise it returns undefined.
 */
var readFile = exports.readFile = _co2.default.wrap( /*#__PURE__*/regeneratorRuntime.mark(function _callee(filepath, cwd, shouldGzip) {
  var stat, fileContents;
  return regeneratorRuntime.wrap(function _callee$(_context) {
    while (1) {
      switch (_context.prev = _context.next) {
        case 0:
          stat = _coFsExtra2.default.statSync(filepath);

          if (!stat.isFile()) {
            _context.next = 7;
            break;
          }

          _context.next = 4;
          return _coFsExtra2.default.readFile(filepath, { encoding: null });

        case 4:
          fileContents = _context.sent;


          if (shouldGzip) {
            fileContents = _zlib2.default.gzipSync(fileContents);
          }

          return _context.abrupt('return', {
            stat: stat,
            contents: fileContents,
            base: _path2.default.join(process.cwd(), cwd),
            path: _path2.default.join(process.cwd(), filepath)
          });

        case 7:
          return _context.abrupt('return', undefined);

        case 8:
        case 'end':
          return _context.stop();
      }
    }
  }, _callee, this);
}));

/**
 * Handles a path, by obtaining file details for a provided path,
 * checking if file is already in AWS bucket and needs updates,
 * and uploading files that are not there yet, or do need an update.
 */
var handleFile = exports.handleFile = _co2.default.wrap( /*#__PURE__*/regeneratorRuntime.mark(function _callee2(filePath, s3Client, s3UploadOpts, _ref2) {
  var filePrefix = _ref2.filePrefix,
      cwd = _ref2.cwd,
      ext = _ref2.ext,
      gzip = _ref2.gzip,
      index = _ref2.index,
      preventUpdates = _ref2.preventUpdates,
      console = _ref2.console;

  var s3UploadOptions, fileObject, aliases, i, name, fileUploadStatus, _name;

  return regeneratorRuntime.wrap(function _callee2$(_context2) {
    while (1) {
      switch (_context2.prev = _context2.next) {
        case 0:
          s3UploadOptions = _extends({}, s3UploadOpts);

          if (shouldBeZipped(filePath, gzip)) s3UploadOptions.ContentEncoding = 'gzip';
          _context2.next = 4;
          return readFile(filePath, cwd, s3UploadOptions.ContentEncoding);

        case 4:
          fileObject = _context2.sent;

          if (!(fileObject !== undefined)) {
            _context2.next = 38;
            break;
          }

          aliases = utils.buildIndexes(fileObject, index);
          _context2.prev = 7;
          _context2.next = 10;
          return sync(s3Client, fileObject, filePrefix, s3UploadOptions, preventUpdates);

        case 10:
          if (!(aliases && aliases.length > 0)) {
            _context2.next = 19;
            break;
          }

          i = 0;

        case 12:
          if (!(i < aliases.length)) {
            _context2.next = 19;
            break;
          }

          name = aliases[i];
          _context2.next = 16;
          return sync(s3Client, fileObject, filePrefix, s3UploadOptions, preventUpdates, name);

        case 16:
          i++;
          _context2.next = 12;
          break;

        case 19:
          _context2.next = 25;
          break;

        case 21:
          _context2.prev = 21;
          _context2.t0 = _context2['catch'](7);

          console.error(_context2.t0);
          return _context2.abrupt('return');

        case 25:
          _context2.next = 27;
          return upload(s3Client, fileObject, s3UploadOptions, filePrefix, ext);

        case 27:
          fileUploadStatus = _context2.sent;

          if (!(aliases && aliases.length > 0)) {
            _context2.next = 37;
            break;
          }

          i = 0;

        case 30:
          if (!(i < aliases.length)) {
            _context2.next = 37;
            break;
          }

          _name = aliases[i];
          _context2.next = 34;
          return upload(s3Client, fileObject, s3UploadOptions, filePrefix, ext, _name);

        case 34:
          i++;
          _context2.next = 30;
          break;

        case 37:
          console.log(fileUploadStatus);

        case 38:
        case 'end':
          return _context2.stop();
      }
    }
  }, _callee2, this, [[7, 21]]);
}));

/**
 * Entry point, creates AWS client, prepares AWS options,
 * and handles all provided paths.
 */
var deploy = exports.deploy = _co2.default.wrap( /*#__PURE__*/regeneratorRuntime.mark(function _callee3(options) {
  var AWSOptions, s3ClientOptions, s3Client, s3UploadOptions, cfOptions;
  return regeneratorRuntime.wrap(function _callee3$(_context3) {
    while (1) {
      switch (_context3.prev = _context3.next) {
        case 0:
          options.console = options.console || global.console;
          AWSOptions = {
            region: options.region
          };

          _awsSdk2.default.config.update(Object.assign({
            sslEnabled: true
          }, AWSOptions));
          if (options.profile) {
            _awsSdk2.default.config.credentials = new _awsSdk2.default.SharedIniFileCredentials({ profile: options.profile });
          }

          s3ClientOptions = {};

          if (options.hasOwnProperty('signatureVersion')) {
            s3ClientOptions.signatureVersion = options.signatureVersion;
          }
          s3Client = new _awsSdk2.default.S3(s3ClientOptions);
          s3UploadOptions = {
            Bucket: options.bucket,
            CacheControl: options.cacheControl
          };

          if (options.hasOwnProperty('etag')) {
            s3UploadOptions.Metadata = {
              ETag: options.etag
            };
          }
          if (options.private) {
            s3UploadOptions.ACL = 'private';
          }

          _context3.next = 12;
          return Promise.all(options.globbedFiles.map(function (filePath) {
            return handleFile(filePath, s3Client, s3UploadOptions, options);
          }));

        case 12:
          cfOptions = {};

          if (options.hasOwnProperty('distId')) {
            cfOptions.distId = options.distId;
            if (options.hasOwnProperty('invalidate')) {
              cfOptions.invalidate = options.invalidate.split(' ');
            }
          }
          if (cfOptions.distId) {
            (0, _cloudfront.invalidate)(cfOptions.distId, cfOptions.invalidate);
          }

          if (options.deleteRemoved) {
            deleteRemoved(s3Client, options.globbedFiles, options);
          }

        case 16:
        case 'end':
          return _context3.stop();
      }
    }
  }, _callee3, this);
}));