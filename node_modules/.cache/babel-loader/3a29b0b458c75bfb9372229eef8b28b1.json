{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"/Users/kenzo/Desktop/3box-dapp/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"/Users/kenzo/Desktop/3box-dapp/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _classCallCheck = require(\"/Users/kenzo/Desktop/3box-dapp/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/kenzo/Desktop/3box-dapp/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nvar _possibleConstructorReturn = require(\"/Users/kenzo/Desktop/3box-dapp/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/possibleConstructorReturn\");\n\nvar _getPrototypeOf = require(\"/Users/kenzo/Desktop/3box-dapp/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/getPrototypeOf\");\n\nvar _inherits = require(\"/Users/kenzo/Desktop/3box-dapp/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/inherits\");\n\nvar pMap = require('p-map');\n\nvar GSet = require('./g-set');\n\nvar Entry = require('./entry');\n\nvar LogIO = require('./log-io');\n\nvar LogError = require('./log-errors');\n\nvar Clock = require('./lamport-clock');\n\nvar isDefined = require('./utils/is-defined');\n\nvar _uniques = require('./utils/uniques');\n\nvar randomId = function randomId() {\n  return new Date().getTime().toString();\n};\n\nvar getHash = function getHash(e) {\n  return e.hash;\n};\n\nvar flatMap = function flatMap(res, acc) {\n  return res.concat(acc);\n};\n\nvar getNextPointers = function getNextPointers(entry) {\n  return entry.next;\n};\n\nvar maxClockTimeReducer = function maxClockTimeReducer(res, acc) {\n  return Math.max(res, acc.clock.time);\n};\n\nvar uniqueEntriesReducer = function uniqueEntriesReducer(res, acc) {\n  res[acc.hash] = acc;\n  return res;\n};\n/**\n * Log\n *\n * @description\n * Log implements a G-Set CRDT and adds ordering\n *\n * From:\n * \"A comprehensive study of Convergent and Commutative Replicated Data Types\"\n * https://hal.inria.fr/inria-00555588\n */\n\n\nvar Log =\n/*#__PURE__*/\nfunction (_GSet) {\n  _inherits(Log, _GSet);\n\n  /**\n   * Create a new Log instance\n   * @param  {IPFS}           ipfs    An IPFS instance\n   * @param  {String}         id      ID of the log\n   * @param  {[Array<Entry>]} entries An Array of Entries from which to create the log from\n   * @param  {[Array<Entry>]} heads   Set the heads of the log\n   * @param  {[Clock]}        clock   Set the clock of the log\n   * @return {Log}            Log\n   */\n  function Log(ipfs, id, entries, heads, clock, key) {\n    var _this;\n\n    var keys = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : [];\n\n    _classCallCheck(this, Log);\n\n    if (!isDefined(ipfs)) {\n      throw LogError.ImmutableDBNotDefinedError();\n    }\n\n    if (isDefined(entries) && !Array.isArray(entries)) {\n      throw new Error(\"'entries' argument must be an array of Entry instances\");\n    }\n\n    if (isDefined(heads) && !Array.isArray(heads)) {\n      throw new Error(\"'heads' argument must be an array\");\n    }\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(Log).call(this));\n    _this._storage = ipfs;\n    _this._id = id || randomId(); // Signing related setup\n\n    _this._keystore = _this._storage.keystore;\n    _this._key = key;\n    _this._keys = Array.isArray(keys) ? keys : [keys]; // Add entries to the internal cache\n\n    entries = entries || [];\n    _this._entryIndex = entries.reduce(uniqueEntriesReducer, {}); // Set heads if not passed as an argument\n\n    heads = heads || Log.findHeads(entries);\n    _this._headsIndex = heads.reduce(uniqueEntriesReducer, {}); // Index of all next pointers in this log\n\n    _this._nextsIndex = {};\n    entries.forEach(function (e) {\n      return e.next.forEach(function (a) {\n        return _this._nextsIndex[a] = e.hash;\n      });\n    }); // Set the length, we calculate the length manually internally\n\n    _this._length = entries ? entries.length : 0; // Set the clock\n\n    var maxTime = Math.max(clock ? clock.time : 0, _this.heads.reduce(maxClockTimeReducer, 0)); // Take the given key as the clock id is it's a Key instance,\n    // otherwise if key was given, take whatever it is,\n    // and if it was null, take the given id as the clock id\n\n    var clockId = key && key.getPublic ? key.getPublic('hex') : key ? key : _this._id;\n    _this._clock = new Clock(clockId, maxTime);\n    return _this;\n  }\n  /**\n   * Returns the ID of the log\n   * @returns {string}\n   */\n\n\n  _createClass(Log, [{\n    key: \"get\",\n\n    /**\n     * Find an entry\n     * @param {string} [hash] The Multihash of the entry as Base58 encoded string\n     * @returns {Entry|undefined}\n     */\n    value: function get(hash) {\n      return this._entryIndex[hash];\n    }\n  }, {\n    key: \"has\",\n    value: function has(entry) {\n      return this._entryIndex[entry.hash || entry] !== undefined;\n    }\n  }, {\n    key: \"traverse\",\n    value: function traverse(rootEntries, amount) {\n      // console.log(\"traverse>\", rootEntry)\n      var stack = rootEntries.map(getNextPointers).reduce(flatMap, []);\n      var traversed = {};\n      var result = {};\n      var count = 0;\n\n      var addToStack = function addToStack(hash) {\n        if (!result[hash] && !traversed[hash]) {\n          stack.push(hash);\n          traversed[hash] = true;\n        }\n      };\n\n      var addRootHash = function addRootHash(rootEntry) {\n        result[rootEntry.hash] = rootEntry.hash;\n        traversed[rootEntry.hash] = true;\n        count++;\n      };\n\n      rootEntries.forEach(addRootHash);\n\n      while (stack.length > 0 && count < amount) {\n        var hash = stack.shift();\n        var entry = this.get(hash);\n\n        if (entry) {\n          count++;\n          result[entry.hash] = entry.hash;\n          traversed[entry.hash] = true;\n          entry.next.forEach(addToStack);\n        }\n      }\n\n      return result;\n    }\n    /**\n     * Append an entry to the log\n     * @param  {Entry} entry Entry to add\n     * @return {Log}   New Log containing the appended value\n     */\n\n  }, {\n    key: \"append\",\n    value: function () {\n      var _append = _asyncToGenerator(\n      /*#__PURE__*/\n      _regeneratorRuntime.mark(function _callee(data) {\n        var _this2 = this;\n\n        var pointerCount,\n            newTime,\n            nexts,\n            entry,\n            _args = arguments;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                pointerCount = _args.length > 1 && _args[1] !== undefined ? _args[1] : 1;\n\n                if (!(this._key && this._key.getPublic && !this._keys.includes(this._key.getPublic('hex')) && !this._keys.includes('*'))) {\n                  _context.next = 3;\n                  break;\n                }\n\n                throw new Error(\"Not allowed to write\");\n\n              case 3:\n                // Update the clock (find the latest clock)\n                newTime = Math.max(this.clock.time, this.heads.reduce(maxClockTimeReducer, 0)) + 1;\n                this._clock = new Clock(this.clock.id, newTime); // Get the required amount of hashes to next entries (as per current state of the log)\n\n                nexts = Object.keys(this.traverse(this.heads, pointerCount)); // Create the entry and add it to the internal cache\n\n                _context.next = 8;\n                return Entry.create(this._storage, this._keystore, this.id, data, nexts, this.clock, this._key);\n\n              case 8:\n                entry = _context.sent;\n                this._entryIndex[entry.hash] = entry;\n                nexts.forEach(function (e) {\n                  return _this2._nextsIndex[e] = entry.hash;\n                });\n                this._headsIndex = {};\n                this._headsIndex[entry.hash] = entry; // Update the length\n\n                this._length++;\n                return _context.abrupt(\"return\", entry);\n\n              case 15:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function append(_x) {\n        return _append.apply(this, arguments);\n      }\n\n      return append;\n    }()\n    /**\n     * Join two logs\n     *\n     * @description Joins two logs returning a new log. Doesn't mutate the original logs.\n     *\n     * @param {IPFS}   [ipfs] An IPFS instance\n     * @param {Log}    log    Log to join with this Log\n     * @param {Number} [size] Max size of the joined log\n     * @param {string} [id]   ID to use for the new log\n     *\n     * @example\n     * log1.join(log2)\n     *\n     * @returns {Promise<Log>}\n     */\n\n  }, {\n    key: \"join\",\n    value: function () {\n      var _join = _asyncToGenerator(\n      /*#__PURE__*/\n      _regeneratorRuntime.mark(function _callee4(log) {\n        var _this3 = this;\n\n        var size,\n            verifyEntries,\n            difference,\n            newItems,\n            canJoin,\n            addToNextsIndex,\n            tmp,\n            notReferencedByNewItems,\n            notInCurrentNexts,\n            nextsFromNewItems,\n            mergedHeads,\n            maxClock,\n            _args4 = arguments;\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                size = _args4.length > 1 && _args4[1] !== undefined ? _args4[1] : -1;\n\n                if (isDefined(log)) {\n                  _context4.next = 3;\n                  break;\n                }\n\n                throw LogError.LogNotDefinedError();\n\n              case 3:\n                if (Log.isLog(log)) {\n                  _context4.next = 5;\n                  break;\n                }\n\n                throw LogError.NotALogError();\n\n              case 5:\n                // Verify the entries\n                // TODO: move to Entry\n                verifyEntries =\n                /*#__PURE__*/\n                function () {\n                  var _ref = _asyncToGenerator(\n                  /*#__PURE__*/\n                  _regeneratorRuntime.mark(function _callee3(entries) {\n                    var isTrue, getPubKey, checkAllKeys, pubkeys, verify, checked;\n                    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n                      while (1) {\n                        switch (_context3.prev = _context3.next) {\n                          case 0:\n                            isTrue = function isTrue(e) {\n                              return e === true;\n                            };\n\n                            getPubKey = function getPubKey(e) {\n                              return e.getPublic ? e.getPublic('hex') : e;\n                            };\n\n                            checkAllKeys = function checkAllKeys(keys, entry) {\n                              var keyMatches = function keyMatches(e) {\n                                return e === entry.key;\n                              };\n\n                              return keys.find(keyMatches);\n                            };\n\n                            pubkeys = _this3._keys.map(getPubKey);\n\n                            verify =\n                            /*#__PURE__*/\n                            function () {\n                              var _ref2 = _asyncToGenerator(\n                              /*#__PURE__*/\n                              _regeneratorRuntime.mark(function _callee2(entry) {\n                                return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n                                  while (1) {\n                                    switch (_context2.prev = _context2.next) {\n                                      case 0:\n                                        if (entry.key) {\n                                          _context2.next = 2;\n                                          break;\n                                        }\n\n                                        throw new Error(\"Entry doesn't have a public key\");\n\n                                      case 2:\n                                        if (entry.sig) {\n                                          _context2.next = 4;\n                                          break;\n                                        }\n\n                                        throw new Error(\"Entry doesn't have a signature\");\n\n                                      case 4:\n                                        if (!(_this3._keys.length === 1 && _this3._keys[0] === _this3._key)) {\n                                          _context2.next = 7;\n                                          break;\n                                        }\n\n                                        if (!(entry.id !== _this3.id)) {\n                                          _context2.next = 7;\n                                          break;\n                                        }\n\n                                        throw new Error(\"Entry doesn't belong in this log (wrong ID)\");\n\n                                      case 7:\n                                        if (!(_this3._keys.length > 0 && !_this3._keys.includes('*') && !checkAllKeys(_this3._keys.concat([_this3._key]), entry))) {\n                                          _context2.next = 10;\n                                          break;\n                                        }\n\n                                        console.warn(\"Warning: Input log contains entries that are not allowed in this log. Logs weren't joined.\");\n                                        return _context2.abrupt(\"return\", false);\n\n                                      case 10:\n                                        _context2.prev = 10;\n                                        _context2.next = 13;\n                                        return Entry.verifyEntry(entry, _this3._keystore);\n\n                                      case 13:\n                                        _context2.next = 18;\n                                        break;\n\n                                      case 15:\n                                        _context2.prev = 15;\n                                        _context2.t0 = _context2[\"catch\"](10);\n                                        throw new Error(\"Invalid signature in entry '\".concat(entry.hash, \"'\"));\n\n                                      case 18:\n                                        return _context2.abrupt(\"return\", true);\n\n                                      case 19:\n                                      case \"end\":\n                                        return _context2.stop();\n                                    }\n                                  }\n                                }, _callee2, this, [[10, 15]]);\n                              }));\n\n                              return function verify(_x4) {\n                                return _ref2.apply(this, arguments);\n                              };\n                            }();\n\n                            _context3.next = 7;\n                            return pMap(entries, verify);\n\n                          case 7:\n                            checked = _context3.sent;\n                            return _context3.abrupt(\"return\", checked.every(isTrue));\n\n                          case 9:\n                          case \"end\":\n                            return _context3.stop();\n                        }\n                      }\n                    }, _callee3, this);\n                  }));\n\n                  return function verifyEntries(_x3) {\n                    return _ref.apply(this, arguments);\n                  };\n                }();\n\n                difference = function difference(log, exclude) {\n                  var stack = Object.keys(log._headsIndex);\n                  var traversed = {};\n                  var res = {};\n\n                  var pushToStack = function pushToStack(hash) {\n                    if (!traversed[hash] && !exclude.get(hash)) {\n                      stack.push(hash);\n                      traversed[hash] = true;\n                    }\n                  };\n\n                  while (stack.length > 0) {\n                    var hash = stack.shift();\n                    var entry = log.get(hash);\n\n                    if (entry && !exclude.get(hash) && entry.id === _this3.id) {\n                      res[entry.hash] = entry;\n                      traversed[entry.hash] = true;\n                      entry.next.forEach(pushToStack);\n                    }\n                  }\n\n                  return res;\n                }; // Merge the entries\n\n\n                newItems = difference(log, this); // if a key was given, verify the entries from the incoming log\n\n                if (!(this._key && this._key.getPublic)) {\n                  _context4.next = 14;\n                  break;\n                }\n\n                _context4.next = 11;\n                return verifyEntries(Object.values(newItems));\n\n              case 11:\n                canJoin = _context4.sent;\n\n                if (canJoin) {\n                  _context4.next = 14;\n                  break;\n                }\n\n                return _context4.abrupt(\"return\", this);\n\n              case 14:\n                // Update the internal entry index\n                this._entryIndex = Object.assign(this._entryIndex, newItems); // Update the internal next pointers index\n\n                addToNextsIndex = function addToNextsIndex(e) {\n                  return e.next.forEach(function (a) {\n                    return _this3._nextsIndex[a] = e.hash;\n                  });\n                };\n\n                Object.values(newItems).forEach(addToNextsIndex); // Update the length\n\n                this._length += Object.values(newItems).length; // Slice to the requested size\n\n                if (size > -1) {\n                  tmp = this.values;\n                  tmp = tmp.slice(-size);\n                  this._entryIndex = tmp.reduce(uniqueEntriesReducer, {});\n                  this._length = Object.values(this._entryIndex).length;\n                } // Merge the heads\n\n\n                notReferencedByNewItems = function notReferencedByNewItems(e) {\n                  return !nextsFromNewItems.find(function (a) {\n                    return a === e.hash;\n                  });\n                };\n\n                notInCurrentNexts = function notInCurrentNexts(e) {\n                  return !_this3._nextsIndex[e.hash];\n                };\n\n                nextsFromNewItems = Object.values(newItems).map(getNextPointers).reduce(flatMap, []);\n                mergedHeads = Log.findHeads(Object.values(Object.assign({}, this._headsIndex, log._headsIndex))).filter(notReferencedByNewItems).filter(notInCurrentNexts).reduce(uniqueEntriesReducer, {});\n                this._headsIndex = mergedHeads; // Find the latest clock from the heads\n\n                maxClock = Object.values(this._headsIndex).reduce(maxClockTimeReducer, 0);\n                this._clock = new Clock(this.clock.id, Math.max(this.clock.time, maxClock));\n                return _context4.abrupt(\"return\", this);\n\n              case 27:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this);\n      }));\n\n      function join(_x2) {\n        return _join.apply(this, arguments);\n      }\n\n      return join;\n    }()\n    /**\n     * Get the log in JSON format\n     * @returns {Object<{heads}>}\n     */\n\n  }, {\n    key: \"toJSON\",\n    value: function toJSON() {\n      return {\n        id: this.id,\n        heads: this.heads.map(getHash)\n      };\n    }\n  }, {\n    key: \"toSnapshot\",\n    value: function toSnapshot() {\n      return {\n        id: this.id,\n        heads: this.heads,\n        values: this.values\n      };\n    }\n    /**\n     * Get the log as a Buffer\n     * @returns {Buffer}\n     */\n\n  }, {\n    key: \"toBuffer\",\n    value: function toBuffer() {\n      return Buffer.from(JSON.stringify(this.toJSON()));\n    }\n    /**\n     * Returns the log entries as a formatted string\n     * @example\n     * two\n     * └─one\n     *   └─three\n     * @returns {string}\n     */\n\n  }, {\n    key: \"toString\",\n    value: function toString(payloadMapper) {\n      var _this4 = this;\n\n      return this.values.slice().reverse().map(function (e, idx) {\n        var parents = Entry.findChildren(e, _this4.values);\n        var len = parents.length;\n        var padding = new Array(Math.max(len - 1, 0));\n        padding = len > 1 ? padding.fill('  ') : padding;\n        padding = len > 0 ? padding.concat(['└─']) : padding;\n        return padding.join('') + (payloadMapper ? payloadMapper(e.payload) : e.payload);\n      }).join('\\n');\n    }\n    /**\n     * Check whether an object is a Log instance\n     * @param {Object} log An object to check\n     * @returns {true|false}\n     */\n\n  }, {\n    key: \"toMultihash\",\n\n    /**\n     * Get the log's multihash\n     * @returns {Promise<string>} Multihash of the Log as Base58 encoded string\n     */\n    value: function toMultihash() {\n      return LogIO.toMultihash(this._storage, this);\n    }\n    /**\n     * Create a log from multihash\n     * @param {IPFS}   ipfs        An IPFS instance\n     * @param {string} hash        Multihash (as a Base58 encoded string) to create the log from\n     * @param {Number} [length=-1] How many items to include in the log\n     * @param {Function(hash, entry, parent, depth)} onProgressCallback\n     * @return {Promise<Log>}      New Log\n     */\n\n  }, {\n    key: \"id\",\n    get: function get() {\n      return this._id;\n    }\n    /**\n     * Returns the clock of the log\n     * @returns {string}\n     */\n\n  }, {\n    key: \"clock\",\n    get: function get() {\n      return this._clock;\n    }\n    /**\n     * Returns the length of the log\n     * @return {Number} Length\n     */\n\n  }, {\n    key: \"length\",\n    get: function get() {\n      return this._length;\n    }\n    /**\n     * Returns the values in the log\n     * @returns {Array<Entry>}\n     */\n\n  }, {\n    key: \"values\",\n    get: function get() {\n      return Object.values(this._entryIndex).sort(Entry.compare) || [];\n    }\n    /**\n     * Returns an array of heads as multihashes\n     * @returns {Array<string>}\n     */\n\n  }, {\n    key: \"heads\",\n    get: function get() {\n      return Object.values(this._headsIndex) || [];\n    }\n    /**\n     * Returns an array of Entry objects that reference entries which\n     * are not in the log currently\n     * @returns {Array<Entry>}\n     */\n\n  }, {\n    key: \"tails\",\n    get: function get() {\n      return Log.findTails(this.values);\n    }\n    /**\n     * Returns an array of multihashes that are referenced by entries which\n     * are not in the log currently\n     * @returns {Array<string>} Array of multihashes\n     */\n\n  }, {\n    key: \"tailHashes\",\n    get: function get() {\n      return Log.findTailHashes(this.values);\n    }\n  }], [{\n    key: \"isLog\",\n    value: function isLog(log) {\n      return log.id !== undefined && log.heads !== undefined && log._entryIndex !== undefined;\n    }\n  }, {\n    key: \"fromMultihash\",\n    value: function fromMultihash(ipfs, hash) {\n      var length = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;\n      var exclude = arguments.length > 3 ? arguments[3] : undefined;\n      var key = arguments.length > 4 ? arguments[4] : undefined;\n      var onProgressCallback = arguments.length > 5 ? arguments[5] : undefined;\n      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError();\n      if (!isDefined(hash)) throw new Error(\"Invalid hash: \".concat(hash)); // TODO: need to verify the entries with 'key'\n\n      return LogIO.fromMultihash(ipfs, hash, length, exclude, onProgressCallback).then(function (data) {\n        return new Log(ipfs, data.id, data.values, data.heads, data.clock, key);\n      });\n    }\n    /**\n     * Create a log from a single entry's multihash\n     * @param {IPFS}   ipfs        An IPFS instance\n     * @param {string} hash        Multihash (as a Base58 encoded string) of the Entry from which to create the log from\n     * @param {Number} [length=-1] How many entries to include in the log\n     * @param {Function(hash, entry, parent, depth)} onProgressCallback\n     * @return {Promise<Log>}      New Log\n     */\n\n  }, {\n    key: \"fromEntryHash\",\n    value: function fromEntryHash(ipfs, hash, id) {\n      var length = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : -1;\n      var exclude = arguments.length > 4 ? arguments[4] : undefined;\n      var key = arguments.length > 5 ? arguments[5] : undefined;\n      var keys = arguments.length > 6 ? arguments[6] : undefined;\n      var onProgressCallback = arguments.length > 7 ? arguments[7] : undefined;\n      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError();\n      if (!isDefined(hash)) throw new Error(\"'hash' must be defined\"); // TODO: need to verify the entries with 'key'\n\n      return LogIO.fromEntryHash(ipfs, hash, id, length, exclude, onProgressCallback).then(function (data) {\n        return new Log(ipfs, id, data.values, null, null, key, keys);\n      });\n    }\n    /**\n     * Create a log from a Log Snapshot JSON\n     * @param {IPFS} ipfs          An IPFS instance\n     * @param {Object} json        Log snapshot as JSON object\n     * @param {Number} [length=-1] How many entries to include in the log\n     * @param {Function(hash, entry, parent, depth)} [onProgressCallback]\n     * @return {Promise<Log>}      New Log\n     */\n\n  }, {\n    key: \"fromJSON\",\n    value: function fromJSON(ipfs, json) {\n      var length = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;\n      var key = arguments.length > 3 ? arguments[3] : undefined;\n      var keys = arguments.length > 4 ? arguments[4] : undefined;\n      var timeout = arguments.length > 5 ? arguments[5] : undefined;\n      var onProgressCallback = arguments.length > 6 ? arguments[6] : undefined;\n      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError(); // TODO: need to verify the entries with 'key'\n\n      return LogIO.fromJSON(ipfs, json, length, key, timeout, onProgressCallback).then(function (data) {\n        return new Log(ipfs, data.id, data.values, null, null, key, keys);\n      });\n    }\n    /**\n     * Create a new log from an Entry instance\n     * @param {IPFS}                ipfs          An IPFS instance\n     * @param {Entry|Array<Entry>}  sourceEntries An Entry or an array of entries to fetch a log from\n     * @param {Number}              [length=-1]   How many entries to include. Default: infinite.\n     * @param {Array<Entry|string>} [exclude]     Array of entries or hashes or entries to not fetch (foe eg. cached entries)\n     * @param {Function(hash, entry, parent, depth)} [onProgressCallback]\n     * @return {Promise<Log>}       New Log\n     */\n\n  }, {\n    key: \"fromEntry\",\n    value: function fromEntry(ipfs, sourceEntries) {\n      var length = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;\n      var exclude = arguments.length > 3 ? arguments[3] : undefined;\n      var onProgressCallback = arguments.length > 4 ? arguments[4] : undefined;\n      if (!isDefined(ipfs)) throw LogError.ImmutableDBNotDefinedError();\n      if (!isDefined(sourceEntries)) throw new Error(\"'sourceEntries' must be defined\"); // TODO: need to verify the entries with 'key'\n\n      return LogIO.fromEntry(ipfs, sourceEntries, length, exclude, onProgressCallback).then(function (data) {\n        return new Log(ipfs, data.id, data.values);\n      });\n    }\n    /**\n     * Find heads from a collection of entries\n     *\n     * @description\n     * Finds entries that are the heads of this collection,\n     * ie. entries that are not referenced by other entries\n     *\n     * @param {Array<Entry>} Entries to search heads from\n     * @returns {Array<Entry>}\n     */\n\n  }, {\n    key: \"findHeads\",\n    value: function findHeads(entries) {\n      var indexReducer = function indexReducer(res, entry, idx, arr) {\n        var addToResult = function addToResult(e) {\n          return res[e] = entry.hash;\n        };\n\n        entry.next.forEach(addToResult);\n        return res;\n      };\n\n      var items = entries.reduce(indexReducer, {});\n\n      var exists = function exists(e) {\n        return items[e.hash] === undefined;\n      };\n\n      var compareIds = function compareIds(a, b) {\n        return a.clock.id > b.clock.id;\n      };\n\n      return entries.filter(exists).sort(compareIds);\n    } // Find entries that point to another entry that is not in the\n    // input array\n\n  }, {\n    key: \"findTails\",\n    value: function findTails(entries) {\n      // Reverse index { next -> entry }\n      var reverseIndex = {}; // Null index containing entries that have no parents (nexts)\n\n      var nullIndex = []; // Hashes for all entries for quick lookups\n\n      var hashes = {}; // Hashes of all next entries\n\n      var nexts = [];\n\n      var addToIndex = function addToIndex(e) {\n        if (e.next.length === 0) {\n          nullIndex.push(e);\n        }\n\n        var addToReverseIndex = function addToReverseIndex(a) {\n          /* istanbul ignore else */\n          if (!reverseIndex[a]) reverseIndex[a] = [];\n          reverseIndex[a].push(e);\n        }; // Add all entries and their parents to the reverse index\n\n\n        e.next.forEach(addToReverseIndex); // Get all next references\n\n        nexts = nexts.concat(e.next); // Get the hashes of input entries\n\n        hashes[e.hash] = true;\n      }; // Create our indices\n\n\n      entries.forEach(addToIndex);\n\n      var addUniques = function addUniques(res, entries, idx, arr) {\n        return res.concat(_uniques(entries, 'hash'));\n      };\n\n      var exists = function exists(e) {\n        return hashes[e] === undefined;\n      };\n\n      var findFromReverseIndex = function findFromReverseIndex(e) {\n        return reverseIndex[e];\n      }; // Drop hashes that are not in the input entries\n\n\n      var tails = nexts // For every multihash in nexts:\n      .filter(exists) // Remove undefineds and nulls\n      .map(findFromReverseIndex) // Get the Entry from the reverse index\n      .reduce(addUniques, []) // Flatten the result and take only uniques\n      .concat(nullIndex); // Combine with tails the have no next refs (ie. first-in-their-chain)\n\n      return _uniques(tails, 'hash').sort(Entry.compare);\n    } // Find the hashes to entries that are not in a collection\n    // but referenced by other entries\n\n  }, {\n    key: \"findTailHashes\",\n    value: function findTailHashes(entries) {\n      var hashes = {};\n\n      var addToIndex = function addToIndex(e) {\n        return hashes[e.hash] = true;\n      };\n\n      var reduceTailHashes = function reduceTailHashes(res, entry, idx, arr) {\n        var addToResult = function addToResult(e) {\n          /* istanbul ignore else */\n          if (hashes[e] === undefined) {\n            res.splice(0, 0, e);\n          }\n        };\n\n        entry.next.reverse().forEach(addToResult);\n        return res;\n      };\n\n      entries.forEach(addToIndex);\n      return entries.reduce(reduceTailHashes, []);\n    }\n  }]);\n\n  return Log;\n}(GSet);\n\nmodule.exports = Log;","map":null,"metadata":{},"sourceType":"script"}