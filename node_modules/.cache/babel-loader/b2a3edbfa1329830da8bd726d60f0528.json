{"ast":null,"code":"'use strict';\n\nvar traverse = require('pull-traverse');\n\nvar UnixFS = require('ipfs-unixfs');\n\nvar CID = require('cids');\n\nvar pull = require('pull-stream');\n\nvar paramap = require('pull-paramap');\n\nvar extractDataFromBlock = require('./extract-data-from-block'); // Logic to export a single (possibly chunked) unixfs file.\n\n\nmodule.exports = function (cid, node, name, path, pathRest, resolve, size, dag, parent, depth, offset, length) {\n  var accepts = pathRest[0];\n\n  if (accepts !== undefined && accepts !== path) {\n    return pull.empty();\n  }\n\n  var file;\n\n  try {\n    file = UnixFS.unmarshal(node.data);\n  } catch (error) {\n    return pull.error(error);\n  }\n\n  var fileSize = size || file.fileSize();\n\n  if (offset < 0) {\n    return pull.error(new Error('Offset must be greater than or equal to 0'));\n  }\n\n  if (offset > fileSize) {\n    return pull.error(new Error('Offset must be less than the file size'));\n  }\n\n  if (length < 0) {\n    return pull.error(new Error('Length must be greater than or equal to 0'));\n  }\n\n  if (length === 0) {\n    return pull.once({\n      depth: depth,\n      content: pull.once(Buffer.alloc(0)),\n      name: name,\n      path: path,\n      hash: cid,\n      size: fileSize,\n      type: 'file'\n    });\n  }\n\n  if (!offset) {\n    offset = 0;\n  }\n\n  if (!length || offset + length > fileSize) {\n    length = fileSize - offset;\n  }\n\n  var content = streamBytes(dag, node, fileSize, offset, length);\n  return pull.values([{\n    depth: depth,\n    content: content,\n    name: name,\n    path: path,\n    hash: cid,\n    size: fileSize,\n    type: 'file'\n  }]);\n};\n\nfunction streamBytes(dag, node, fileSize, offset, length) {\n  if (offset === fileSize || length === 0) {\n    return pull.once(Buffer.alloc(0));\n  }\n\n  var end = offset + length;\n  return pull(traverse.depthFirst({\n    node: node,\n    start: 0,\n    end: fileSize\n  }, getChildren(dag, offset, end)), pull.map(extractData(offset, end)), pull.filter(Boolean));\n}\n\nfunction getChildren(dag, offset, end) {\n  // as we step through the children, keep track of where we are in the stream\n  // so we can filter out nodes we're not interested in\n  var streamPosition = 0;\n  return function visitor(_ref) {\n    var node = _ref.node;\n\n    if (Buffer.isBuffer(node)) {\n      // this is a leaf node, can't traverse any further\n      return pull.empty();\n    }\n\n    var file;\n\n    try {\n      file = UnixFS.unmarshal(node.data);\n    } catch (error) {\n      return pull.error(error);\n    }\n\n    var nodeHasData = Boolean(file.data && file.data.length); // handle case where data is present on leaf nodes and internal nodes\n\n    if (nodeHasData && node.links.length) {\n      streamPosition += file.data.length;\n    } // work out which child nodes contain the requested data\n\n\n    var filteredLinks = node.links.map(function (link, index) {\n      var child = {\n        link: link,\n        start: streamPosition,\n        end: streamPosition + file.blockSizes[index],\n        size: file.blockSizes[index]\n      };\n      streamPosition = child.end;\n      return child;\n    }).filter(function (child) {\n      return offset >= child.start && offset < child.end || // child has offset byte\n      end > child.start && end <= child.end || // child has end byte\n      offset < child.start && end > child.end; // child is between offset and end bytes\n    });\n\n    if (filteredLinks.length) {\n      // move stream position to the first node we're going to return data from\n      streamPosition = filteredLinks[0].start;\n    }\n\n    return pull(pull.values(filteredLinks), paramap(function (child, cb) {\n      dag.get(new CID(child.link.multihash), function (error, result) {\n        return cb(error, {\n          start: child.start,\n          end: child.end,\n          node: result && result.value,\n          size: child.size\n        });\n      });\n    }));\n  };\n}\n\nfunction extractData(requestedStart, requestedEnd) {\n  var streamPosition = -1;\n  return function getData(_ref2) {\n    var node = _ref2.node,\n        start = _ref2.start,\n        end = _ref2.end;\n    var block;\n\n    if (Buffer.isBuffer(node)) {\n      block = node;\n    } else {\n      try {\n        var file = UnixFS.unmarshal(node.data);\n\n        if (!file.data) {\n          if (file.blockSizes.length) {\n            return;\n          }\n\n          return Buffer.alloc(0);\n        }\n\n        block = file.data;\n      } catch (error) {\n        throw new Error(\"Failed to unmarshal node - \".concat(error.message));\n      }\n    }\n\n    if (block && block.length) {\n      if (streamPosition === -1) {\n        streamPosition = start;\n      }\n\n      var output = extractDataFromBlock(block, streamPosition, requestedStart, requestedEnd);\n      streamPosition += block.length;\n      return output;\n    }\n\n    return Buffer.alloc(0);\n  };\n}","map":null,"metadata":{},"sourceType":"script"}